
clone from http://www.fit.vutbr.cz/~imikolov/rnnlm/rnn-rt07-example.tar.gz

Is it what I want?
==================
If you want to see some easy examples how to train/use RNN language models use Tom Mikolovs introductory examples instead.
These are advanced examples for those, who trained already their models, and want to see how to
run fast RNN rescoring/adaptation experiments on some own data. 
We require some additional tool here which does faster rescoring and model loading than the rnnlm tool written in plain C.
It depends on Nokia Qt 4.6 or higher!

About the data:
===============
Here are given three example scripts how to do rescoring + adaptation using 100-best lists from the NIST rt07seval set.
This data was used in the last NIST RT evaluations in 2007 and 2009 [1,2].
N-bests were extracted using the lattices of our baseline recognizer (RT09) with lattice tool 
The RNN model provided here is the one described in [3].
Since HResults is used for scoring, numbers are worse than what we reported in our papers (where NIST scoring is used).
Hence, obtained improvements differ slightly.

Required:
========
About 15G free disk space for running adaptation, 1-2G for anything else
rnn_rescore (Qt 4.6, QtCore only)
rnnlm (for ex3.sh only)

Scoring -- IMPORTANT!!!
=======================
Due to licensing issues we are not allowed to redistribute the transcripts for the rt07eval test set.
You can however request the MLF file needed for scoring from us provided you can show us a valid agreement with LDC which entitles you to use this data.
So far we have put there a dummy file which will give you 100% WER for all results.
Please ask Jonathan Fiscus from NIST (jonathan.fiscus@nist.gov) about giving you permissions or find a licensing agreement with his help.

========
Each of these scripts will have a runtime of between 5-30 minutes depending on how fast your computer is.
For a reference (expected output, speed, memory consumption) check out file benchmark.txt

1.sh - simple rnn rescoring run, interpolation with LM scores using equal weights
2.sh - rnn rescoring using multiple weights, linear combination and linear interpolation of log-scores
3.sh - adaptation and second pass rnn rescoring using the one-best from run2.sh (thus needed to be run before that!)
getbest.sh - create 1-best MLF given nbest list, scores and LMS/WIP
scoring.sh - shows performance (ngram,rnn+ngram,rnn,adapt)
eval.sh - simple comparison of WERs after all examples have been processed

Other files:
============
README.TXT - you read it!
benchmark.txt - screen dump for the examples on my computer, plus info about runtime and memory consumption

ams - acoustic model scores
lm.prob - RT09 LM probabilities estimated for the n-best (column=words,lines nbest hypotheses)
nbest.txt - 100-best hypotheses generated by our system 
rnn_rescore-0.1 - fast rescoring tool written in C++ (uses Qt 4.6/Eigen)
rnnlm - fast training tool written in C (no dependencies)
rt07seval.ref.mlf - reference transcript MLF
rt09.rnn - RNN model (rnnlm text format)

What to do?
===========
convert the text format rnn model into binary format required for rnn_rescore (ca. 1 min)
rnn_rescore-0.1/rnn_rescore -convert rt09.rnn rt09.bin

OPTIONAL: if you have several machines you can find the fastest one using this benchmark (1/2 min):
rnn_rescore-0.1/rnn_rescore -benchmark rt09.bin  

for a fast and simple example of RNN rescoring run (ca. 15 min)
./1.sh 

for rescoring with wide range interpolation run (ca. 15 min)
./2.sh

after ex2.sh was run, adaptation and a subsequent second rescoring pass can be applied
./3.sh (ca. 30 min)

compare WERs
./eval.sh 

Contact:
========
For questions about these scripts/rnn_rescore tool:
Stefan Kombrink
kombrink@fit.vutbr.cz

For questions about RNN theory/rnnlm tool: 
Tomas Mikolov 
imikolov@fit.vutbr.cz
